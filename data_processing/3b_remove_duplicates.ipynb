{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "699ee610-8f28-478e-9899-0346acbdd080",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T17:33:59.635688Z",
     "iopub.status.busy": "2024-05-07T17:33:59.635308Z",
     "iopub.status.idle": "2024-05-07T17:34:11.893799Z",
     "shell.execute_reply": "2024-05-07T17:34:11.892884Z",
     "shell.execute_reply.started": "2024-05-07T17:33:59.635662Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "def deg_to_cartesian(ra, dec):\n",
    "    ra = np.radians(ra)\n",
    "    dec = np.radians(dec)\n",
    "    return np.cos(ra) * np.cos(dec), np.sin(ra) * np.cos(dec), np.sin(dec)\n",
    "\n",
    "tolerance = 1/3600\n",
    "tolerance_rad = np.radians(tolerance)\n",
    "\n",
    "h5_dir = '/arc/projects/ots/HSC_h5/'\n",
    "\n",
    "#filenames = ['HSC_dud_galaxy_calexp_GIRYZ7610_64.h5', \n",
    "#             'HSC_dud_qso_calexp_GIRYZ7610_64.h5',\n",
    "#             'HSC_dud_star_calexp_GIRYZ7610_64.h5',\n",
    "#             'HSC_dud_dwarf_galaxy_calexp_GIRYZ7610_64.h5',\n",
    "#             'HSC_dud_unknown_calexp_GIRYZ7610_64.h5']\n",
    "filenames = ['HSC_dud_galaxy_GIRYZ7610_64.h5', \n",
    "             'HSC_dud_qso_GIRYZ7610_64.h5',\n",
    "             'HSC_dud_star_GIRYZ7610_64.h5',\n",
    "             'HSC_dud_dwarf_galaxy_GIRYZ7610_64.h5',\n",
    "             'HSC_dud_unknown_GIRYZ7610_64.h5']\n",
    "\n",
    "# Store Cartesian coordinates and original indices\n",
    "xyz = []\n",
    "original_indices = []\n",
    "for fn in filenames:\n",
    "    with h5py.File(os.path.join(h5_dir, fn), \"r\") as f:\n",
    "        ra = f['ra'][:]\n",
    "        dec = f['dec'][:]\n",
    "        x, y, z = deg_to_cartesian(ra, dec)\n",
    "        xyz.append(np.vstack((x, y, z)).T)\n",
    "        original_indices.append(np.arange(len(ra)))  # Original indices\n",
    "\n",
    "# Function to remove duplicates within each dataset\n",
    "def remove_duplicates_within(data, tolerance_rad):\n",
    "    tree = cKDTree(data)\n",
    "    indices_to_keep = []\n",
    "    indices_already_checked = set()\n",
    "    \n",
    "    for i in range(data.shape[0]):\n",
    "        if i in indices_already_checked:\n",
    "            continue\n",
    "        # Find points within tolerance\n",
    "        indices_within = tree.query_ball_point(data[i], r=tolerance_rad)\n",
    "        indices_to_keep.append(indices_within[0])  # Keep the first index\n",
    "        indices_already_checked.update(indices_within)\n",
    "        \n",
    "    return np.array(indices_to_keep)\n",
    "\n",
    "# Step 1: Remove duplicates within each dataset and collect good indices\n",
    "good_indices_within = [remove_duplicates_within(data, tolerance_rad) for data in xyz]\n",
    "\n",
    "# Step 2: Remove matches across datasets\n",
    "final_good_indices = [good_indices.copy() for good_indices in good_indices_within]\n",
    "\n",
    "for i in range(len(xyz)):\n",
    "    for j in range(i + 1, len(xyz)):\n",
    "        if len(final_good_indices[i]) == 0 or len(final_good_indices[j]) == 0:\n",
    "            continue\n",
    "        \n",
    "        data_i = xyz[i][final_good_indices[i]]\n",
    "        data_j = xyz[j][final_good_indices[j]]\n",
    "        \n",
    "        tree_i = cKDTree(data_i)\n",
    "        tree_j = cKDTree(data_j)\n",
    "        \n",
    "        matches_i = tree_i.query_ball_tree(tree_j, r=tolerance_rad)\n",
    "        matches_j = tree_j.query_ball_tree(tree_i, r=tolerance_rad)\n",
    "        \n",
    "        # Indices to keep (those not in matches)\n",
    "        keep_i = set(range(len(data_i))) - set(np.concatenate(matches_i))\n",
    "        keep_j = set(range(len(data_j))) - set(np.concatenate(matches_j))\n",
    "        \n",
    "        # Update final good indices after cross-dataset check\n",
    "        final_good_indices[i] = final_good_indices[i][list(keep_i)]\n",
    "        final_good_indices[j] = final_good_indices[j][list(keep_j)]\n",
    "\n",
    "# final_good_indices contains lists of indices for each dataset that are considered \"good\"\n",
    "# These indices can be used to extract the \"good\" points from the original datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab270ecd-166c-462d-930e-d4f63fea0fdb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T17:35:09.595782Z",
     "iopub.status.busy": "2024-05-07T17:35:09.595456Z",
     "iopub.status.idle": "2024-05-07T18:12:10.347243Z",
     "shell.execute_reply": "2024-05-07T18:12:10.263220Z",
     "shell.execute_reply.started": "2024-05-07T17:35:09.595759Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, fn in enumerate(filenames):\n",
    "    original_path = os.path.join(h5_dir, fn)\n",
    "    new_path = os.path.join(h5_dir, fn.replace('.h5', '_new.h5'))\n",
    "    \n",
    "    with h5py.File(original_path, 'r') as original_file, h5py.File(new_path, 'w') as new_file:\n",
    "        good_indices = final_good_indices[i]\n",
    "        \n",
    "        for dataset_name in original_file.keys():\n",
    "            original_dataset = original_file[dataset_name]\n",
    "            shape = original_dataset.shape\n",
    "            dtype = original_dataset.dtype\n",
    "            \n",
    "            # Adjust the shape for the new dataset based on the number of good indices\n",
    "            new_shape = (len(good_indices),) + shape[1:]\n",
    "            new_dataset = new_file.create_dataset(dataset_name, shape=new_shape, dtype=dtype)\n",
    "            \n",
    "            # Copy attributes from the original dataset to the new one\n",
    "            for attr_name, attr_value in original_dataset.attrs.items():\n",
    "                new_dataset.attrs[attr_name] = attr_value\n",
    "            \n",
    "            # Write each good data point to the new dataset one by one\n",
    "            for j, index in enumerate(good_indices):\n",
    "                new_dataset[j] = original_dataset[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b24837b6-4563-471a-9cbc-30c30e50923a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T18:12:10.539326Z",
     "iopub.status.busy": "2024-05-07T18:12:10.539105Z",
     "iopub.status.idle": "2024-05-07T18:12:10.566582Z",
     "shell.execute_reply": "2024-05-07T18:12:10.565970Z",
     "shell.execute_reply.started": "2024-05-07T18:12:10.539304Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.25"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51c3ba3f-2807-4bc9-98fc-2b2a5b69193b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T22:14:47.638126Z",
     "iopub.status.busy": "2024-04-05T22:14:47.637911Z",
     "iopub.status.idle": "2024-04-05T22:14:47.643551Z",
     "shell.execute_reply": "2024-04-05T22:14:47.642640Z",
     "shell.execute_reply.started": "2024-04-05T22:14:47.638106Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[147927, 23366, 59896, 8, 437154]\n",
      "[53853, 9281, 25598, 8, 199766]\n",
      "[53434, 9250, 25586, 8, 197906]\n"
     ]
    }
   ],
   "source": [
    "print([len(_) for _ in xyz])\n",
    "print([len(_) for _ in good_indices_within])\n",
    "print([len(_) for _ in final_good_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f779b18-efc1-4a7f-8e66-71a7c6fbe8f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T20:30:50.650804Z",
     "iopub.status.busy": "2024-04-05T20:30:50.650328Z",
     "iopub.status.idle": "2024-04-05T20:30:51.479380Z",
     "shell.execute_reply": "2024-04-05T20:30:51.477883Z",
     "shell.execute_reply.started": "2024-04-05T20:30:50.650767Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "def deg_to_cartesian(ra, dec):\n",
    "    # Convert RA and DEC to radians for spatial indexing\n",
    "    ra = np.radians(ra)\n",
    "    dec = np.radians(dec)\n",
    "    # Convert to Cartesian coordinates\n",
    "    return np.cos(ra) * np.cos(dec), np.sin(ra) * np.cos(dec), np.sin(dec)\n",
    "\n",
    "tolerance = 1/3600  # Tolerance in degrees\n",
    "tolerance_rad = np.radians(tolerance)  # Convert tolerance to radians\n",
    "\n",
    "h5_dir = '/arc/projects/ots/HSC_h5/'\n",
    "\n",
    "filenames = ['HSC_dud_galaxy_calexp_GIRYZ7610_64.h5', \n",
    "             'HSC_dud_qso_calexp_GIRYZ7610_64.h5',\n",
    "             'HSC_dud_star_calexp_GIRYZ7610_64.h5',\n",
    "             'HSC_dud_dwarf_galaxy_calexp_GIRYZ7610_64.h5',\n",
    "             'HSC_dud_unknown_calexp_GIRYZ7610_64.h5']\n",
    "\n",
    "xyz = []\n",
    "for fn in filenames:\n",
    "    with h5py.File(os.path.join(h5_dir, fn), \"r\") as f:\n",
    "        ra = f['ra'][:]\n",
    "        dec = f['dec'][:]\n",
    "    \n",
    "        # Convert RA and Dec to Cartesian\n",
    "        x, y, z = deg_to_cartesian(ra, dec)\n",
    "        xyz.append(np.vstack((x, y, z)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "727798a7-6ce4-4c79-91c6-df6d7affbfaf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T20:39:16.343926Z",
     "iopub.status.busy": "2024-04-05T20:39:16.343479Z",
     "iopub.status.idle": "2024-04-05T20:39:24.705454Z",
     "shell.execute_reply": "2024-04-05T20:39:24.704436Z",
     "shell.execute_reply.started": "2024-04-05T20:39:16.343889Z"
    }
   },
   "outputs": [],
   "source": [
    "h5_dir = '/arc/projects/ots/HSC_h5/'\n",
    "\n",
    "filenames = ['HSC_dud_galaxy_calexp_GIRYZ7610_64.h5', \n",
    "             'HSC_dud_qso_calexp_GIRYZ7610_64.h5',\n",
    "             'HSC_dud_star_calexp_GIRYZ7610_64.h5',\n",
    "             'HSC_dud_dwarf_galaxy_calexp_GIRYZ7610_64.h5',\n",
    "             'HSC_dud_unknown_calexp_GIRYZ7610_64.h5']\n",
    "\n",
    "xyz = []\n",
    "for fn in filenames:\n",
    "    with h5py.File(os.path.join(h5_dir, fn), \"r\") as f:\n",
    "        ra = f['ra'][:]\n",
    "        dec = f['dec'][:]\n",
    "    \n",
    "        # Convert RA and Dec to Cartesian\n",
    "        x, y, z = deg_to_cartesian(ra, dec)\n",
    "        xyz.append(np.vstack((x, y, z)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebefecfc-2a3b-4066-bb3d-ae240a39e22e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T20:42:06.077402Z",
     "iopub.status.busy": "2024-04-05T20:42:06.075587Z",
     "iopub.status.idle": "2024-04-05T20:42:06.089753Z",
     "shell.execute_reply": "2024-04-05T20:42:06.088556Z",
     "shell.execute_reply.started": "2024-04-05T20:42:06.077373Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(147927, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xyz[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "694509d2-1a63-49b6-9c12-6ea8063ff020",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-07T18:15:38.490063Z",
     "iopub.status.busy": "2024-04-07T18:15:38.489549Z",
     "iopub.status.idle": "2024-04-07T18:15:38.495799Z",
     "shell.execute_reply": "2024-04-07T18:15:38.495042Z",
     "shell.execute_reply.started": "2024-04-07T18:15:38.490026Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.384"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "64/(1000/256 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5f3e1d-0d75-4caf-a768-1b641205d78c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
