{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5ade69e3-5797-4e8a-926d-ea5df1fec01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from astropy.visualization import simple_norm\n",
    "from multiprocessing import Value\n",
    "import torch\n",
    "from torch.utils.data import IterableDataset, DataLoader\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from skimage.segmentation import find_boundaries\n",
    "import time\n",
    "import h5py\n",
    "import os\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "\n",
    "_GLOBAL_SEED = 0\n",
    "\n",
    "class MaskCollator(object):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size=(224, 224),\n",
    "        patch_size=16,\n",
    "        enc_mask_scale=(0.2, 0.8),\n",
    "        pred_mask_scale=(0.2, 0.8),\n",
    "        aspect_ratio=(0.3, 3.0),\n",
    "        nenc=1,\n",
    "        npred=2,\n",
    "        min_keep=4,\n",
    "        allow_overlap=False\n",
    "    ):\n",
    "        super(MaskCollator, self).__init__()\n",
    "        if not isinstance(input_size, tuple):\n",
    "            input_size = (input_size, ) * 2\n",
    "        self.patch_size = patch_size\n",
    "        self.height, self.width = input_size[0] // patch_size, input_size[1] // patch_size\n",
    "        self.enc_mask_scale = enc_mask_scale\n",
    "        self.pred_mask_scale = pred_mask_scale\n",
    "        self.aspect_ratio = aspect_ratio\n",
    "        self.nenc = nenc\n",
    "        self.npred = npred\n",
    "        self.min_keep = min_keep  # minimum number of patches to keep\n",
    "        self.allow_overlap = allow_overlap  # whether to allow overlap b/w enc and pred masks\n",
    "        self._itr_counter = Value('i', -1)  # collator is shared across worker processes\n",
    "        self.generator = torch.Generator()  # Initialize a generator\n",
    "        self.generator.manual_seed(int(time.time()))  # Seed the generator once\n",
    "\n",
    "    def step(self):\n",
    "        i = self._itr_counter\n",
    "        with i.get_lock():\n",
    "            i.value += 1\n",
    "            v = i.value\n",
    "        return v\n",
    "\n",
    "    def _sample_block_size(self, generator, scale, aspect_ratio_scale):\n",
    "        _rand = torch.rand(1, generator=generator).item()\n",
    "        # -- Sample block scale\n",
    "        min_s, max_s = scale\n",
    "        mask_scale = min_s + _rand * (max_s - min_s)\n",
    "        max_keep = int(self.height * self.width * mask_scale)\n",
    "        # -- Sample block aspect-ratio\n",
    "        min_ar, max_ar = aspect_ratio_scale\n",
    "        aspect_ratio = min_ar + _rand * (max_ar - min_ar)\n",
    "        # -- Compute block height and width (given scale and aspect-ratio)\n",
    "        h = int(round(math.sqrt(max_keep * aspect_ratio)))\n",
    "        w = int(round(math.sqrt(max_keep / aspect_ratio)))\n",
    "        while h >= self.height:\n",
    "            h -= 1\n",
    "        while w >= self.width:\n",
    "            w -= 1\n",
    "\n",
    "        return (h, w)\n",
    "\n",
    "    def _sample_block_mask(self, b_size, acceptable_regions=None):\n",
    "        h, w = b_size\n",
    "\n",
    "        def constrain_mask(mask, tries=0):\n",
    "            \"\"\" Helper to restrict given mask to a set of acceptable regions \"\"\"\n",
    "            N = max(int(len(acceptable_regions)-tries), 0)\n",
    "            for k in range(N):\n",
    "                mask *= acceptable_regions[k]\n",
    "        # --\n",
    "        # -- Loop to sample masks until we find a valid one\n",
    "        tries = 0\n",
    "        timeout = og_timeout = 20\n",
    "        valid_mask = False\n",
    "        while not valid_mask:\n",
    "            # -- Sample block top-left corner\n",
    "            top = torch.randint(0, self.height - h + 1, (1,))\n",
    "            left = torch.randint(0, self.width - w + 1, (1,))\n",
    "            max_top = self.height - h\n",
    "            max_left = self.width - w\n",
    "            mask = torch.zeros((self.height, self.width), dtype=torch.int32)\n",
    "            mask[top:top+h, left:left+w] = 1\n",
    "            # -- Constrain mask to a set of acceptable regions\n",
    "            if acceptable_regions is not None:\n",
    "                constrain_mask(mask, tries)\n",
    "            mask = torch.nonzero(mask.flatten())\n",
    "            # -- If mask too small try again\n",
    "            valid_mask = len(mask) > self.min_keep\n",
    "            if not valid_mask:\n",
    "                timeout -= 1\n",
    "                if timeout == 0:\n",
    "                    tries += 1\n",
    "                    timeout = og_timeout\n",
    "                    print(f'Mask generator says: \"Valid mask not found, decreasing acceptable-regions [{tries}]\"')\n",
    "        mask = mask.squeeze()\n",
    "        # --\n",
    "        mask_complement = torch.ones((self.height, self.width), dtype=torch.int32)\n",
    "        mask_complement[top:top+h, left:left+w] = 0\n",
    "        # --\n",
    "        return mask, mask_complement\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        '''\n",
    "        Create encoder and predictor masks when collating imgs into a batch\n",
    "        # 1. sample enc block (size + location) using seed\n",
    "        # 2. sample pred block (size) using seed\n",
    "        # 3. sample several enc block locations for each image (w/o seed)\n",
    "        # 4. sample several pred block locations for each image (w/o seed)\n",
    "        # 5. return enc mask and pred mask\n",
    "        '''\n",
    "        collated_batch = torch.utils.data.default_collate(batch)\n",
    "        \n",
    "        if len(collated_batch) == 2:\n",
    "            collated_images = collated_batch[0]\n",
    "            collated_metadata = collated_batch[1]\n",
    "        else:\n",
    "            collated_images = collated_batch\n",
    "            collated_metadata = torch.zeros(len(collated_batch))\n",
    "        B = len(batch)\n",
    "        \n",
    "        seed = self.step()\n",
    "        g = torch.Generator()\n",
    "        g.manual_seed(seed)\n",
    "        p_size = self._sample_block_size(\n",
    "            generator=g,\n",
    "            scale=self.pred_mask_scale,\n",
    "            aspect_ratio_scale=self.aspect_ratio)\n",
    "        e_size = self._sample_block_size(\n",
    "            generator=g,\n",
    "            scale=self.enc_mask_scale,\n",
    "            aspect_ratio_scale=(1., 1.))\n",
    "\n",
    "        collated_masks_pred, collated_masks_enc = [], []\n",
    "        min_keep_pred = self.height * self.width\n",
    "        min_keep_enc = self.height * self.width\n",
    "        for _ in range(B):\n",
    "\n",
    "            masks_p, masks_C = [], []\n",
    "            for _ in range(self.npred):\n",
    "                mask, mask_C = self._sample_block_mask(p_size)\n",
    "                masks_p.append(mask)\n",
    "                masks_C.append(mask_C)\n",
    "                min_keep_pred = min(min_keep_pred, len(mask))\n",
    "            collated_masks_pred.append(masks_p)\n",
    "\n",
    "            acceptable_regions = masks_C\n",
    "            \n",
    "            try:\n",
    "                if self.allow_overlap:\n",
    "                    acceptable_regions = None\n",
    "            except Exception as e:\n",
    "                print(f'Encountered exception in mask-generator {e}')\n",
    "\n",
    "            masks_e = []\n",
    "            for _ in range(self.nenc):\n",
    "                mask, _ = self._sample_block_mask(e_size, acceptable_regions=acceptable_regions)\n",
    "                masks_e.append(mask)\n",
    "                min_keep_enc = min(min_keep_enc, len(mask))\n",
    "            collated_masks_enc.append(masks_e)\n",
    "\n",
    "        collated_masks_pred = [[cm[:min_keep_pred] for cm in cm_list] for cm_list in collated_masks_pred]\n",
    "        collated_masks_pred = torch.utils.data.default_collate(collated_masks_pred)\n",
    "        # --\n",
    "        collated_masks_enc = [[cm[:min_keep_enc] for cm in cm_list] for cm_list in collated_masks_enc]\n",
    "        collated_masks_enc = torch.utils.data.default_collate(collated_masks_enc)\n",
    "\n",
    "        return collated_images, collated_metadata, collated_masks_enc, collated_masks_pred\n",
    "\n",
    "def load_images(batch_size=4):\n",
    "    # Transform to normalize the data\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    \n",
    "    # Load CIFAR10 images\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                            download=True, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                              shuffle=True, num_workers=2)\n",
    "    # Fetch one batch of images\n",
    "    dataiter = iter(trainloader)\n",
    "    images, _ = next(dataiter)\n",
    "    return list(images)\n",
    "\n",
    "def upscale_mask(mask, patch_size):\n",
    "    upscaled_mask = mask.repeat_interleave(patch_size, dim=0)\n",
    "    upscaled_mask = upscaled_mask.repeat_interleave(patch_size, dim=1)\n",
    "    return upscaled_mask\n",
    "\n",
    "def visualize_masks(images, masks, masks_p, patch_size, alpha_grid, patch_grid=False):\n",
    "    fig, axs = plt.subplots(nrows=len(images), ncols=3, figsize=(10, len(images) * 4))\n",
    "    for i, (img, mask_indices, mask_indices_p) in enumerate(zip(images, masks, masks_p)):\n",
    "        if images.shape[1] == 5:\n",
    "            # only plot r-band\n",
    "            img = img[2].detach().cpu().numpy()\n",
    "            norm = simple_norm(img, 'sqrt', percent=98.)\n",
    "            axs[i, 0].imshow(img, cmap='gray_r', norm=norm)\n",
    "        else:\n",
    "            img = img.permute(1, 2, 0).detach().cpu().numpy()  # Change CxHxW to HxWxC for plotting\n",
    "            axs[i, 0].imshow(img)\n",
    "        \n",
    "        #axs[i, 0].set_xlim(0, img.shape[0])\n",
    "        #axs[i, 0].set_ylim(0, img.shape[1])\n",
    "        axs[i, 0].set_title('Original Image')\n",
    "        axs[i, 0].axis('off')\n",
    "        \n",
    "        if patch_grid:\n",
    "            for x in range(0, img.shape[0]+1, patch_size):\n",
    "                axs[i, 0].axvline(x, color='black', linestyle='--', lw=0.2, alpha=alpha_grid)  # Adjust color and line style if needed\n",
    "            for y in range(0, img.shape[1]+1, patch_size):\n",
    "                axs[i, 0].axhline(y, color='black', linestyle='--', lw=0.2, alpha=alpha_grid)  # Adjust color and line style if needed\n",
    "    \n",
    "            for x in range(0, img.shape[0]+1, patch_size):\n",
    "                axs[i, 1].axvline(x, color='black', linestyle='--', lw=0.2, alpha=alpha_grid)  # Adjust color and line style if needed\n",
    "            for y in range(0, img.shape[1]+1, patch_size):\n",
    "                axs[i, 1].axhline(y, color='black', linestyle='--', lw=0.2, alpha=alpha_grid)  # Adjust color and line style if needed\n",
    "\n",
    "            for x in range(0, img.shape[0]+1, patch_size):\n",
    "                axs[i, 2].axvline(x, color='black', linestyle='--', lw=0.2, alpha=alpha_grid)  # Adjust color and line style if needed\n",
    "            for y in range(0, img.shape[1]+1, patch_size):\n",
    "                axs[i, 2].axhline(y, color='black', linestyle='--', lw=0.2, alpha=alpha_grid)  # Adjust color and line style if needed\n",
    "        \n",
    "        full_mask = torch.zeros(mask_collator.height, mask_collator.width, dtype=torch.float32)\n",
    "        for idx in mask_indices:\n",
    "            row = idx // mask_collator.width\n",
    "            col = idx % mask_collator.width\n",
    "            full_mask[row, col] = 1\n",
    "        \n",
    "        part_masks_p = torch.zeros(mask_indices_p.shape[0], mask_collator.height, mask_collator.width, dtype=torch.float32)\n",
    "        for j, part_mask in enumerate(mask_indices_p):\n",
    "            for idx in part_mask:\n",
    "                row = idx // mask_collator.width\n",
    "                col = idx % mask_collator.width\n",
    "                part_masks_p[j, row, col] = 1\n",
    "        \n",
    "        # Upscale mask to match image resolution\n",
    "        full_mask = upscale_mask(full_mask, mask_collator.patch_size)\n",
    "\n",
    "        part_masks_p = torch.stack([upscale_mask(sub_mask, mask_collator.patch_size) for sub_mask in part_masks_p])\n",
    "        full_mask_p = torch.any(part_masks_p, dim=0)\n",
    "        \n",
    "        # Apply semi-transparent mask\n",
    "        masked_img = img.copy()\n",
    "        full_mask = full_mask.detach().cpu().numpy()\n",
    "        alpha = 0.6  # transparency level\n",
    "        # color_mask = np.ones_like(img) * [1, 0, 0]  # red mask\n",
    "        # masked_img[full_mask == 0] = masked_img[full_mask == 0] * (1 - alpha) + color_mask[full_mask == 0] * alpha\n",
    "        if images.shape[1] == 5:\n",
    "            axs[i, 1].imshow(masked_img, cmap='gray_r', norm=norm)\n",
    "        else:\n",
    "            axs[i, 1].imshow(masked_img)\n",
    "        axs[i, 1].imshow(np.ma.masked_where(full_mask == 1, full_mask), cmap='cool', vmin=-1, alpha=alpha)\n",
    "        axs[i, 1].set_title('Final context mask')\n",
    "        axs[i, 1].axis('off')\n",
    "\n",
    "        masked_img_p = img.copy()\n",
    "        # masked_img_p[full_mask_p == 0] = masked_img_p[full_mask_p == 0] * (1 - alpha) + color_mask[full_mask_p == 0] * alpha\n",
    "        full_mask_p = full_mask_p.detach().cpu().numpy()\n",
    "        if images.shape[1] == 5:\n",
    "            axs[i, 2].imshow(masked_img_p, cmap='gray_r', norm=norm)\n",
    "        else:\n",
    "            axs[i, 2].imshow(masked_img_p)\n",
    "        axs[i, 2].imshow(np.ma.masked_where(full_mask_p == 0, full_mask_p), cmap='cool', vmin=0, alpha=alpha, interpolation='none')\n",
    "        all_mask_boundaries = np.zeros(full_mask_p.shape, dtype='bool')\n",
    "        for k in range(part_masks_p.shape[0]):\n",
    "            mask_boundaries = find_boundaries(part_masks_p[k].detach().cpu().numpy(), mode='thin')\n",
    "            all_mask_boundaries |= mask_boundaries\n",
    "        axs[i, 2].imshow(np.ma.masked_where(all_mask_boundaries==0, all_mask_boundaries), cmap='cool', vmin=1, alpha=alpha, interpolation='none')\n",
    "        axs[i, 2].set_title('Target masks')\n",
    "        axs[i, 2].axis('off')\n",
    "    plt.show()\n",
    "    return mask_boundaries\n",
    "\n",
    "def read_h5(cutout_dir):\n",
    "    \"\"\"\n",
    "    Reads cutout data from HDF5 file\n",
    "    :param cutout_dir: cutout directory\n",
    "    :return: cutout data\n",
    "    \"\"\"\n",
    "    with h5py.File(cutout_dir, 'r') as f:\n",
    "        # Create empty dictionaries to store data for each group\n",
    "        cutout_data = {}\n",
    "\n",
    "        # Loop through datasets\n",
    "        for dataset_name in f:\n",
    "            data = np.array(f[dataset_name])\n",
    "            cutout_data[dataset_name] = data\n",
    "    return cutout_data\n",
    "\n",
    "class RealTileDataset(IterableDataset):\n",
    "    def __init__(self, cutouts, metadata):\n",
    "        \"\"\"\n",
    "        Initializes the dataset with real data.\n",
    "\n",
    "        Args:\n",
    "        cutouts (Tensor): A tensor or list of image data.\n",
    "        metadata (Tensor): A tensor or list of corresponding metadata.\n",
    "        \"\"\"\n",
    "        catalog = tensor_compatible(metadata)\n",
    "        cutouts = torch.tensor(cutouts, dtype=torch.float32)\n",
    "        catalog = torch.tensor(catalog.values, dtype=torch.float32)\n",
    "        self.cutouts = cutouts\n",
    "        self.metadata = catalog\n",
    "\n",
    "    def __iter__(self):\n",
    "        for cutout, meta in zip(self.cutouts, self.metadata):\n",
    "            yield cutout, meta\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the total number of items in the dataset\n",
    "        return len(self.cutouts)\n",
    "\n",
    "def convert_to_binary(input_string):\n",
    "    # Define the standard order of letters\n",
    "    standard_letters = 'ugriz'\n",
    "    # Initialize the result as an empty string\n",
    "    result = ''\n",
    "    # Iterate over each letter in the standard order\n",
    "    for letter in standard_letters:\n",
    "        # Append '2' if the letter is in the input string, '1' otherwise\n",
    "        if letter in input_string:\n",
    "            result += '2'\n",
    "        else:\n",
    "            result += '1'\n",
    "    # Convert the binary string to a decimal integer\n",
    "    return np.int32(result)\n",
    "\n",
    "\n",
    "def split_tile_nums(df):\n",
    "    # Split the tuple into two separate columns\n",
    "    if isinstance(df['tile'][0], str):\n",
    "        df['tile'] = df['tile'].apply(ast.literal_eval)\n",
    "    df['tile_num1'], df['tile_num2'] = zip(*df['tile'])\n",
    "    # Drop tile column\n",
    "    df.drop('tile', axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def tensor_compatible(df):\n",
    "    # Convert band info to integer number, 2 -> present, 1 -> absent\n",
    "    if isinstance(df['bands'][0], str):\n",
    "        df['bands'] = df['bands'].apply(convert_to_binary)\n",
    "    if 'tile' in df.columns:\n",
    "        # Split tile numbers up to two different columns and delete the tile column\n",
    "        df = split_tile_nums(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c86946d-7a15-42ce-b03b-afaf7651ede9",
   "metadata": {},
   "source": [
    "### Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8337abc4-9487-40e4-a111-2b60dfa2999f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size=(224, 224)\n",
    "patch_size=8\n",
    "enc_mask_scale=(0.85, 1.0)\n",
    "pred_mask_scale=(0.02, 0.15)\n",
    "aspect_ratio=(0.5, 1.5)\n",
    "nenc=1\n",
    "npred=6\n",
    "min_keep=10\n",
    "height, width = input_size[0] // patch_size, input_size[1] // patch_size\n",
    "alpha_grid = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3794ef-6b28-4f74-b907-a607d0a610f3",
   "metadata": {},
   "source": [
    "### Cutouts & Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "60e51ab6-8317-4c2e-be44-5c06ca878b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/home/nick/astro/sky_embeddings/data'\n",
    "cutouts = read_h5(os.path.join(root,'154_328_224x224_ugriz.h5'))\n",
    "catalog = pd.read_csv(os.path.join(root,'(154, 328)_catalog.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced6013a-edd8-496f-a04c-23c9030e59ea",
   "metadata": {},
   "source": [
    "### Initialize Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6cbce149-3fb5-4f9d-83b0-0986a7d050c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_collator = MaskCollator(\n",
    "input_size=input_size,\n",
    "patch_size=patch_size,\n",
    "pred_mask_scale=pred_mask_scale,\n",
    "enc_mask_scale=enc_mask_scale,\n",
    "aspect_ratio=aspect_ratio,\n",
    "nenc=nenc,\n",
    "npred=npred,\n",
    "allow_overlap=False,\n",
    "min_keep=min_keep)\n",
    "\n",
    "dataset = RealTileDataset(cutouts=cutouts['images'], metadata=catalog)\n",
    "#dist_sampler = torch.utils.data.distributed.DistributedSampler(dataset=dataset, num_replicas=1, rank=0)\n",
    "dataloader = torch.utils.data.DataLoader(  # type: ignore\n",
    "    dataset,\n",
    "    batch_size=10,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    drop_last=True,\n",
    "    shuffle=False,\n",
    "    collate_fn=mask_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7f9dbcb3-a892-4bfa-a515-591b9d9bd9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes: images torch.Size([10, 5, 224, 224]), metadata: torch.Size([10, 13]), mask_enc: torch.Size([1, 10, 315]), masks_pred: torch.Size([6, 10, 72])\n",
      "shapes: images torch.Size([10, 5, 224, 224]), metadata: torch.Size([10, 13]), mask_enc: torch.Size([1, 10, 232]), masks_pred: torch.Size([6, 10, 117])\n",
      "shapes: images torch.Size([10, 5, 224, 224]), metadata: torch.Size([10, 13]), mask_enc: torch.Size([1, 10, 314]), masks_pred: torch.Size([6, 10, 90])\n",
      "shapes: images torch.Size([10, 5, 224, 224]), metadata: torch.Size([10, 13]), mask_enc: torch.Size([1, 10, 276]), masks_pred: torch.Size([6, 10, 99])\n",
      "shapes: images torch.Size([10, 5, 224, 224]), metadata: torch.Size([10, 13]), mask_enc: torch.Size([1, 10, 351]), masks_pred: torch.Size([6, 10, 72])\n",
      "shapes: images torch.Size([10, 5, 224, 224]), metadata: torch.Size([10, 13]), mask_enc: torch.Size([1, 10, 268]), masks_pred: torch.Size([6, 10, 108])\n",
      "shapes: images torch.Size([10, 5, 224, 224]), metadata: torch.Size([10, 13]), mask_enc: torch.Size([1, 10, 272]), masks_pred: torch.Size([6, 10, 117])\n",
      "shapes: images torch.Size([10, 5, 224, 224]), metadata: torch.Size([10, 13]), mask_enc: torch.Size([1, 10, 410]), masks_pred: torch.Size([6, 10, 56])\n",
      "shapes: images torch.Size([10, 5, 224, 224]), metadata: torch.Size([10, 13]), mask_enc: torch.Size([1, 10, 375]), masks_pred: torch.Size([6, 10, 64])\n",
      "shapes: images torch.Size([10, 5, 224, 224]), metadata: torch.Size([10, 13]), mask_enc: torch.Size([1, 10, 366]), masks_pred: torch.Size([6, 10, 72])\n"
     ]
    }
   ],
   "source": [
    "image_list = []\n",
    "meta_list = []\n",
    "mask_enc_list = []\n",
    "mask_p_list = []\n",
    "\n",
    "for images, meta, masks_enc, masks_p in dataloader:\n",
    "    image_list.append(images)\n",
    "    meta_list.append(meta)\n",
    "    mask_enc_list.append(masks_enc)\n",
    "    mask_p_list.append(masks_p)\n",
    "    print(f'shapes: images {images.shape}, metadata: {meta.shape}, mask_enc: {torch.stack(masks_enc).shape}, masks_pred: {torch.stack(masks_p).shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4f826e9f-be97-48a6-a367-ccfd5181945a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 5, 224, 224]), torch.Size([10, 72]))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.squeeze(1).shape, masks_p[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5891c75d-a1de-43a9-a358-212ff23737e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "images_in = load_images(batch_size=4)\n",
    "\n",
    "mask_collator = MaskCollator(\n",
    "input_size=input_size,\n",
    "patch_size=patch_size,\n",
    "pred_mask_scale=pred_mask_scale,\n",
    "enc_mask_scale=enc_mask_scale,\n",
    "aspect_ratio=aspect_ratio,\n",
    "nenc=nenc,\n",
    "npred=npred,\n",
    "allow_overlap=False,\n",
    "min_keep=min_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "186995a6-ce0e-4505-99b7-9f335595fecb",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [420] at entry 0 and [433] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[82], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m images, meta, masks_enc, masks_p \u001b[38;5;241m=\u001b[39m \u001b[43mmask_collator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages_in\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshapes: images: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimages\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, meta: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmeta\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, masks_enc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmasks_enc[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, masks_p: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch\u001b[38;5;241m.\u001b[39mstack(masks_p)\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "Cell \u001b[0;32mIn[76], line 180\u001b[0m, in \u001b[0;36mMaskCollator.__call__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# --\u001b[39;00m\n\u001b[1;32m    179\u001b[0m collated_masks_enc \u001b[38;5;241m=\u001b[39m [cm[:min_keep_enc] \u001b[38;5;28;01mfor\u001b[39;00m cm \u001b[38;5;129;01min\u001b[39;00m collated_masks_enc]\n\u001b[0;32m--> 180\u001b[0m collated_masks_enc \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault_collate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcollated_masks_enc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m collated_images, collated_metadata, collated_masks_enc, collated_masks_pred\n",
      "File \u001b[0;32m~/anaconda3/envs/skyembeddings/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:316\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    256\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/skyembeddings/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:182\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    180\u001b[0m     clone \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mcopy(elem)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, samples \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(transposed):\n\u001b[0;32m--> 182\u001b[0m         clone[i] \u001b[38;5;241m=\u001b[39m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m clone\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/skyembeddings/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:141\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m--> 141\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m    144\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[0;32m~/anaconda3/envs/skyembeddings/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:213\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    211\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    212\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[0;32m--> 213\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [420] at entry 0 and [433] at entry 1"
     ]
    }
   ],
   "source": [
    "images, meta, masks_enc, masks_p = mask_collator(images_in)\n",
    "print(f'shapes: images: {images.shape}, meta: {meta.shape}, masks_enc: {masks_enc[0].shape}, masks_p: {torch.stack(masks_p).shape}')\n",
    "idx = 2\n",
    "#images, meta, masks_enc, masks_p = image_list[idx], meta_list[idx], mask_enc_list[idx], mask_p_list[idx]\n",
    "stacked_masks_p = torch.stack(masks_p)\n",
    "reshaped_masks = torch.unbind(stacked_masks_p, dim=1)\n",
    "# Just use one set of encoder masks for demonstration\n",
    "mask_indices_p = full_mask_p = visualize_masks(images, masks_enc[0], reshaped_masks, patch_size, alpha_grid, patch_grid=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "13f0c098-2eb8-4996-aa51-496e673b961c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 293])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks_enc[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3f9b6890-6e2d-4c65-a658-dbbcf14a0d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 99])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks_p[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e9f91dec-e9fb-40c1-bfd1-78b85872ed24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[146, 147, 148, 149, 150, 151, 152, 153, 154, 174, 175, 176, 177, 178,\n",
       "          179, 180, 181, 182, 202, 203, 204, 205, 206, 207, 208, 209, 210, 230,\n",
       "          231, 232, 233, 234, 235, 236, 237, 238, 258, 259, 260, 261, 262, 263,\n",
       "          264, 265, 266, 286, 287, 288, 289, 290, 291, 292, 293, 294, 314, 315,\n",
       "          316, 317, 318, 319, 320, 321, 322, 342, 343, 344, 345, 346, 347, 348,\n",
       "          349, 350, 370, 371, 372, 373, 374, 375, 376, 377, 378, 398, 399, 400,\n",
       "          401, 402, 403, 404, 405, 406, 426, 427, 428, 429, 430, 431, 432, 433,\n",
       "          434],\n",
       "         [311, 312, 313, 314, 315, 316, 317, 318, 319, 339, 340, 341, 342, 343,\n",
       "          344, 345, 346, 347, 367, 368, 369, 370, 371, 372, 373, 374, 375, 395,\n",
       "          396, 397, 398, 399, 400, 401, 402, 403, 423, 424, 425, 426, 427, 428,\n",
       "          429, 430, 431, 451, 452, 453, 454, 455, 456, 457, 458, 459, 479, 480,\n",
       "          481, 482, 483, 484, 485, 486, 487, 507, 508, 509, 510, 511, 512, 513,\n",
       "          514, 515, 535, 536, 537, 538, 539, 540, 541, 542, 543, 563, 564, 565,\n",
       "          566, 567, 568, 569, 570, 571, 591, 592, 593, 594, 595, 596, 597, 598,\n",
       "          599],\n",
       "         [327, 328, 329, 330, 331, 332, 333, 334, 335, 355, 356, 357, 358, 359,\n",
       "          360, 361, 362, 363, 383, 384, 385, 386, 387, 388, 389, 390, 391, 411,\n",
       "          412, 413, 414, 415, 416, 417, 418, 419, 439, 440, 441, 442, 443, 444,\n",
       "          445, 446, 447, 467, 468, 469, 470, 471, 472, 473, 474, 475, 495, 496,\n",
       "          497, 498, 499, 500, 501, 502, 503, 523, 524, 525, 526, 527, 528, 529,\n",
       "          530, 531, 551, 552, 553, 554, 555, 556, 557, 558, 559, 579, 580, 581,\n",
       "          582, 583, 584, 585, 586, 587, 607, 608, 609, 610, 611, 612, 613, 614,\n",
       "          615],\n",
       "         [486, 487, 488, 489, 490, 491, 492, 493, 494, 514, 515, 516, 517, 518,\n",
       "          519, 520, 521, 522, 542, 543, 544, 545, 546, 547, 548, 549, 550, 570,\n",
       "          571, 572, 573, 574, 575, 576, 577, 578, 598, 599, 600, 601, 602, 603,\n",
       "          604, 605, 606, 626, 627, 628, 629, 630, 631, 632, 633, 634, 654, 655,\n",
       "          656, 657, 658, 659, 660, 661, 662, 682, 683, 684, 685, 686, 687, 688,\n",
       "          689, 690, 710, 711, 712, 713, 714, 715, 716, 717, 718, 738, 739, 740,\n",
       "          741, 742, 743, 744, 745, 746, 766, 767, 768, 769, 770, 771, 772, 773,\n",
       "          774]]),\n",
       " tensor([[280, 281, 282, 283, 284, 285, 286, 287, 288, 308, 309, 310, 311, 312,\n",
       "          313, 314, 315, 316, 336, 337, 338, 339, 340, 341, 342, 343, 344, 364,\n",
       "          365, 366, 367, 368, 369, 370, 371, 372, 392, 393, 394, 395, 396, 397,\n",
       "          398, 399, 400, 420, 421, 422, 423, 424, 425, 426, 427, 428, 448, 449,\n",
       "          450, 451, 452, 453, 454, 455, 456, 476, 477, 478, 479, 480, 481, 482,\n",
       "          483, 484, 504, 505, 506, 507, 508, 509, 510, 511, 512, 532, 533, 534,\n",
       "          535, 536, 537, 538, 539, 540, 560, 561, 562, 563, 564, 565, 566, 567,\n",
       "          568],\n",
       "         [ 31,  32,  33,  34,  35,  36,  37,  38,  39,  59,  60,  61,  62,  63,\n",
       "           64,  65,  66,  67,  87,  88,  89,  90,  91,  92,  93,  94,  95, 115,\n",
       "          116, 117, 118, 119, 120, 121, 122, 123, 143, 144, 145, 146, 147, 148,\n",
       "          149, 150, 151, 171, 172, 173, 174, 175, 176, 177, 178, 179, 199, 200,\n",
       "          201, 202, 203, 204, 205, 206, 207, 227, 228, 229, 230, 231, 232, 233,\n",
       "          234, 235, 255, 256, 257, 258, 259, 260, 261, 262, 263, 283, 284, 285,\n",
       "          286, 287, 288, 289, 290, 291, 311, 312, 313, 314, 315, 316, 317, 318,\n",
       "          319],\n",
       "         [267, 268, 269, 270, 271, 272, 273, 274, 275, 295, 296, 297, 298, 299,\n",
       "          300, 301, 302, 303, 323, 324, 325, 326, 327, 328, 329, 330, 331, 351,\n",
       "          352, 353, 354, 355, 356, 357, 358, 359, 379, 380, 381, 382, 383, 384,\n",
       "          385, 386, 387, 407, 408, 409, 410, 411, 412, 413, 414, 415, 435, 436,\n",
       "          437, 438, 439, 440, 441, 442, 443, 463, 464, 465, 466, 467, 468, 469,\n",
       "          470, 471, 491, 492, 493, 494, 495, 496, 497, 498, 499, 519, 520, 521,\n",
       "          522, 523, 524, 525, 526, 527, 547, 548, 549, 550, 551, 552, 553, 554,\n",
       "          555],\n",
       "         [  9,  10,  11,  12,  13,  14,  15,  16,  17,  37,  38,  39,  40,  41,\n",
       "           42,  43,  44,  45,  65,  66,  67,  68,  69,  70,  71,  72,  73,  93,\n",
       "           94,  95,  96,  97,  98,  99, 100, 101, 121, 122, 123, 124, 125, 126,\n",
       "          127, 128, 129, 149, 150, 151, 152, 153, 154, 155, 156, 157, 177, 178,\n",
       "          179, 180, 181, 182, 183, 184, 185, 205, 206, 207, 208, 209, 210, 211,\n",
       "          212, 213, 233, 234, 235, 236, 237, 238, 239, 240, 241, 261, 262, 263,\n",
       "          264, 265, 266, 267, 268, 269, 289, 290, 291, 292, 293, 294, 295, 296,\n",
       "          297]]),\n",
       " tensor([[296, 297, 298, 299, 300, 301, 302, 303, 304, 324, 325, 326, 327, 328,\n",
       "          329, 330, 331, 332, 352, 353, 354, 355, 356, 357, 358, 359, 360, 380,\n",
       "          381, 382, 383, 384, 385, 386, 387, 388, 408, 409, 410, 411, 412, 413,\n",
       "          414, 415, 416, 436, 437, 438, 439, 440, 441, 442, 443, 444, 464, 465,\n",
       "          466, 467, 468, 469, 470, 471, 472, 492, 493, 494, 495, 496, 497, 498,\n",
       "          499, 500, 520, 521, 522, 523, 524, 525, 526, 527, 528, 548, 549, 550,\n",
       "          551, 552, 553, 554, 555, 556, 576, 577, 578, 579, 580, 581, 582, 583,\n",
       "          584],\n",
       "         [367, 368, 369, 370, 371, 372, 373, 374, 375, 395, 396, 397, 398, 399,\n",
       "          400, 401, 402, 403, 423, 424, 425, 426, 427, 428, 429, 430, 431, 451,\n",
       "          452, 453, 454, 455, 456, 457, 458, 459, 479, 480, 481, 482, 483, 484,\n",
       "          485, 486, 487, 507, 508, 509, 510, 511, 512, 513, 514, 515, 535, 536,\n",
       "          537, 538, 539, 540, 541, 542, 543, 563, 564, 565, 566, 567, 568, 569,\n",
       "          570, 571, 591, 592, 593, 594, 595, 596, 597, 598, 599, 619, 620, 621,\n",
       "          622, 623, 624, 625, 626, 627, 647, 648, 649, 650, 651, 652, 653, 654,\n",
       "          655],\n",
       "         [ 63,  64,  65,  66,  67,  68,  69,  70,  71,  91,  92,  93,  94,  95,\n",
       "           96,  97,  98,  99, 119, 120, 121, 122, 123, 124, 125, 126, 127, 147,\n",
       "          148, 149, 150, 151, 152, 153, 154, 155, 175, 176, 177, 178, 179, 180,\n",
       "          181, 182, 183, 203, 204, 205, 206, 207, 208, 209, 210, 211, 231, 232,\n",
       "          233, 234, 235, 236, 237, 238, 239, 259, 260, 261, 262, 263, 264, 265,\n",
       "          266, 267, 287, 288, 289, 290, 291, 292, 293, 294, 295, 315, 316, 317,\n",
       "          318, 319, 320, 321, 322, 323, 343, 344, 345, 346, 347, 348, 349, 350,\n",
       "          351],\n",
       "         [374, 375, 376, 377, 378, 379, 380, 381, 382, 402, 403, 404, 405, 406,\n",
       "          407, 408, 409, 410, 430, 431, 432, 433, 434, 435, 436, 437, 438, 458,\n",
       "          459, 460, 461, 462, 463, 464, 465, 466, 486, 487, 488, 489, 490, 491,\n",
       "          492, 493, 494, 514, 515, 516, 517, 518, 519, 520, 521, 522, 542, 543,\n",
       "          544, 545, 546, 547, 548, 549, 550, 570, 571, 572, 573, 574, 575, 576,\n",
       "          577, 578, 598, 599, 600, 601, 602, 603, 604, 605, 606, 626, 627, 628,\n",
       "          629, 630, 631, 632, 633, 634, 654, 655, 656, 657, 658, 659, 660, 661,\n",
       "          662]]),\n",
       " tensor([[238, 239, 240, 241, 242, 243, 244, 245, 246, 266, 267, 268, 269, 270,\n",
       "          271, 272, 273, 274, 294, 295, 296, 297, 298, 299, 300, 301, 302, 322,\n",
       "          323, 324, 325, 326, 327, 328, 329, 330, 350, 351, 352, 353, 354, 355,\n",
       "          356, 357, 358, 378, 379, 380, 381, 382, 383, 384, 385, 386, 406, 407,\n",
       "          408, 409, 410, 411, 412, 413, 414, 434, 435, 436, 437, 438, 439, 440,\n",
       "          441, 442, 462, 463, 464, 465, 466, 467, 468, 469, 470, 490, 491, 492,\n",
       "          493, 494, 495, 496, 497, 498, 518, 519, 520, 521, 522, 523, 524, 525,\n",
       "          526],\n",
       "         [ 96,  97,  98,  99, 100, 101, 102, 103, 104, 124, 125, 126, 127, 128,\n",
       "          129, 130, 131, 132, 152, 153, 154, 155, 156, 157, 158, 159, 160, 180,\n",
       "          181, 182, 183, 184, 185, 186, 187, 188, 208, 209, 210, 211, 212, 213,\n",
       "          214, 215, 216, 236, 237, 238, 239, 240, 241, 242, 243, 244, 264, 265,\n",
       "          266, 267, 268, 269, 270, 271, 272, 292, 293, 294, 295, 296, 297, 298,\n",
       "          299, 300, 320, 321, 322, 323, 324, 325, 326, 327, 328, 348, 349, 350,\n",
       "          351, 352, 353, 354, 355, 356, 376, 377, 378, 379, 380, 381, 382, 383,\n",
       "          384],\n",
       "         [409, 410, 411, 412, 413, 414, 415, 416, 417, 437, 438, 439, 440, 441,\n",
       "          442, 443, 444, 445, 465, 466, 467, 468, 469, 470, 471, 472, 473, 493,\n",
       "          494, 495, 496, 497, 498, 499, 500, 501, 521, 522, 523, 524, 525, 526,\n",
       "          527, 528, 529, 549, 550, 551, 552, 553, 554, 555, 556, 557, 577, 578,\n",
       "          579, 580, 581, 582, 583, 584, 585, 605, 606, 607, 608, 609, 610, 611,\n",
       "          612, 613, 633, 634, 635, 636, 637, 638, 639, 640, 641, 661, 662, 663,\n",
       "          664, 665, 666, 667, 668, 669, 689, 690, 691, 692, 693, 694, 695, 696,\n",
       "          697],\n",
       "         [340, 341, 342, 343, 344, 345, 346, 347, 348, 368, 369, 370, 371, 372,\n",
       "          373, 374, 375, 376, 396, 397, 398, 399, 400, 401, 402, 403, 404, 424,\n",
       "          425, 426, 427, 428, 429, 430, 431, 432, 452, 453, 454, 455, 456, 457,\n",
       "          458, 459, 460, 480, 481, 482, 483, 484, 485, 486, 487, 488, 508, 509,\n",
       "          510, 511, 512, 513, 514, 515, 516, 536, 537, 538, 539, 540, 541, 542,\n",
       "          543, 544, 564, 565, 566, 567, 568, 569, 570, 571, 572, 592, 593, 594,\n",
       "          595, 596, 597, 598, 599, 600, 620, 621, 622, 623, 624, 625, 626, 627,\n",
       "          628]]),\n",
       " tensor([[185, 186, 187, 188, 189, 190, 191, 192, 193, 213, 214, 215, 216, 217,\n",
       "          218, 219, 220, 221, 241, 242, 243, 244, 245, 246, 247, 248, 249, 269,\n",
       "          270, 271, 272, 273, 274, 275, 276, 277, 297, 298, 299, 300, 301, 302,\n",
       "          303, 304, 305, 325, 326, 327, 328, 329, 330, 331, 332, 333, 353, 354,\n",
       "          355, 356, 357, 358, 359, 360, 361, 381, 382, 383, 384, 385, 386, 387,\n",
       "          388, 389, 409, 410, 411, 412, 413, 414, 415, 416, 417, 437, 438, 439,\n",
       "          440, 441, 442, 443, 444, 445, 465, 466, 467, 468, 469, 470, 471, 472,\n",
       "          473],\n",
       "         [152, 153, 154, 155, 156, 157, 158, 159, 160, 180, 181, 182, 183, 184,\n",
       "          185, 186, 187, 188, 208, 209, 210, 211, 212, 213, 214, 215, 216, 236,\n",
       "          237, 238, 239, 240, 241, 242, 243, 244, 264, 265, 266, 267, 268, 269,\n",
       "          270, 271, 272, 292, 293, 294, 295, 296, 297, 298, 299, 300, 320, 321,\n",
       "          322, 323, 324, 325, 326, 327, 328, 348, 349, 350, 351, 352, 353, 354,\n",
       "          355, 356, 376, 377, 378, 379, 380, 381, 382, 383, 384, 404, 405, 406,\n",
       "          407, 408, 409, 410, 411, 412, 432, 433, 434, 435, 436, 437, 438, 439,\n",
       "          440],\n",
       "         [ 61,  62,  63,  64,  65,  66,  67,  68,  69,  89,  90,  91,  92,  93,\n",
       "           94,  95,  96,  97, 117, 118, 119, 120, 121, 122, 123, 124, 125, 145,\n",
       "          146, 147, 148, 149, 150, 151, 152, 153, 173, 174, 175, 176, 177, 178,\n",
       "          179, 180, 181, 201, 202, 203, 204, 205, 206, 207, 208, 209, 229, 230,\n",
       "          231, 232, 233, 234, 235, 236, 237, 257, 258, 259, 260, 261, 262, 263,\n",
       "          264, 265, 285, 286, 287, 288, 289, 290, 291, 292, 293, 313, 314, 315,\n",
       "          316, 317, 318, 319, 320, 321, 341, 342, 343, 344, 345, 346, 347, 348,\n",
       "          349],\n",
       "         [172, 173, 174, 175, 176, 177, 178, 179, 180, 200, 201, 202, 203, 204,\n",
       "          205, 206, 207, 208, 228, 229, 230, 231, 232, 233, 234, 235, 236, 256,\n",
       "          257, 258, 259, 260, 261, 262, 263, 264, 284, 285, 286, 287, 288, 289,\n",
       "          290, 291, 292, 312, 313, 314, 315, 316, 317, 318, 319, 320, 340, 341,\n",
       "          342, 343, 344, 345, 346, 347, 348, 368, 369, 370, 371, 372, 373, 374,\n",
       "          375, 376, 396, 397, 398, 399, 400, 401, 402, 403, 404, 424, 425, 426,\n",
       "          427, 428, 429, 430, 431, 432, 452, 453, 454, 455, 456, 457, 458, 459,\n",
       "          460]]),\n",
       " tensor([[396, 397, 398, 399, 400, 401, 402, 403, 404, 424, 425, 426, 427, 428,\n",
       "          429, 430, 431, 432, 452, 453, 454, 455, 456, 457, 458, 459, 460, 480,\n",
       "          481, 482, 483, 484, 485, 486, 487, 488, 508, 509, 510, 511, 512, 513,\n",
       "          514, 515, 516, 536, 537, 538, 539, 540, 541, 542, 543, 544, 564, 565,\n",
       "          566, 567, 568, 569, 570, 571, 572, 592, 593, 594, 595, 596, 597, 598,\n",
       "          599, 600, 620, 621, 622, 623, 624, 625, 626, 627, 628, 648, 649, 650,\n",
       "          651, 652, 653, 654, 655, 656, 676, 677, 678, 679, 680, 681, 682, 683,\n",
       "          684],\n",
       "         [168, 169, 170, 171, 172, 173, 174, 175, 176, 196, 197, 198, 199, 200,\n",
       "          201, 202, 203, 204, 224, 225, 226, 227, 228, 229, 230, 231, 232, 252,\n",
       "          253, 254, 255, 256, 257, 258, 259, 260, 280, 281, 282, 283, 284, 285,\n",
       "          286, 287, 288, 308, 309, 310, 311, 312, 313, 314, 315, 316, 336, 337,\n",
       "          338, 339, 340, 341, 342, 343, 344, 364, 365, 366, 367, 368, 369, 370,\n",
       "          371, 372, 392, 393, 394, 395, 396, 397, 398, 399, 400, 420, 421, 422,\n",
       "          423, 424, 425, 426, 427, 428, 448, 449, 450, 451, 452, 453, 454, 455,\n",
       "          456],\n",
       "         [ 47,  48,  49,  50,  51,  52,  53,  54,  55,  75,  76,  77,  78,  79,\n",
       "           80,  81,  82,  83, 103, 104, 105, 106, 107, 108, 109, 110, 111, 131,\n",
       "          132, 133, 134, 135, 136, 137, 138, 139, 159, 160, 161, 162, 163, 164,\n",
       "          165, 166, 167, 187, 188, 189, 190, 191, 192, 193, 194, 195, 215, 216,\n",
       "          217, 218, 219, 220, 221, 222, 223, 243, 244, 245, 246, 247, 248, 249,\n",
       "          250, 251, 271, 272, 273, 274, 275, 276, 277, 278, 279, 299, 300, 301,\n",
       "          302, 303, 304, 305, 306, 307, 327, 328, 329, 330, 331, 332, 333, 334,\n",
       "          335],\n",
       "         [487, 488, 489, 490, 491, 492, 493, 494, 495, 515, 516, 517, 518, 519,\n",
       "          520, 521, 522, 523, 543, 544, 545, 546, 547, 548, 549, 550, 551, 571,\n",
       "          572, 573, 574, 575, 576, 577, 578, 579, 599, 600, 601, 602, 603, 604,\n",
       "          605, 606, 607, 627, 628, 629, 630, 631, 632, 633, 634, 635, 655, 656,\n",
       "          657, 658, 659, 660, 661, 662, 663, 683, 684, 685, 686, 687, 688, 689,\n",
       "          690, 691, 711, 712, 713, 714, 715, 716, 717, 718, 719, 739, 740, 741,\n",
       "          742, 743, 744, 745, 746, 747, 767, 768, 769, 770, 771, 772, 773, 774,\n",
       "          775]])]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "603191b5-d359-437a-9f5b-06fac5446e3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 99])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks_p[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "1b159775-107b-4045-82f9-300ae9b70230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([279.7404,  73.7502])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta[0][3:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "bd632aca-2865-4e21-859d-181ea0eb1c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([279.6951,  73.7498]),\n",
       " tensor([278.9959,  73.7484]),\n",
       " tensor([278.8341,  73.7476]))"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta[2][3:5], meta[3][3:5], meta[4][3:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5e2917b-4e4a-4fed-84a4-ea6fba20e46e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "4d2bd3b4-3367-4970-8e35-804ff5f86c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/home/nick/astro/sky_embeddings'\n",
    "tile_cat = pd.read_csv(os.path.join(root, '(150, 322)_catalog.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "5b07764e-33e8-4b21-9d3d-f4e468cea509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas(ID=1, x=7216.109, y=202.7967, ra=230.0196166, dec=70.7521278, mag_r=14.492716, bands=22222, _7=1.0, zspec=-9.359808609588072e-05, lens=nan, lsb=nan, tile_num1=150, tile_num2=322)\n",
      "Pandas(ID=2, x=7859.331, y=145.4179, ra=229.9190009, dec=70.7489498, mag_r=14.93888, bands=22222, _7=1.0, zspec=-0.0002071432973025, lens=nan, lsb=nan, tile_num1=150, tile_num2=322)\n",
      "Pandas(ID=3, x=2550.8567, y=149.6538, ra=230.7498303, dec=70.7493132, mag_r=18.307415, bands=22222, _7=2.0, zspec=0.2250169962644577, lens=nan, lsb=nan, tile_num1=150, tile_num2=322)\n",
      "Pandas(ID=4, x=5071.8354, y=138.8921, ra=230.3552686, dec=70.7491567, mag_r=15.6933365, bands=22222, _7=nan, zspec=nan, lens=nan, lsb=nan, tile_num1=150, tile_num2=322)\n",
      "Pandas(ID=5, x=7765.232, y=132.1593, ra=229.9337425, dec=70.7483008, mag_r=18.250532, bands=22222, _7=2.0, zspec=0.0768089964985847, lens=nan, lsb=nan, tile_num1=150, tile_num2=322)\n",
      "Pandas(ID=6, x=3870.8833, y=101.8959, ra=230.5432114, dec=70.7471632, mag_r=17.612999, bands=22222, _7=2.0, zspec=0.183967113494873, lens=nan, lsb=nan, tile_num1=150, tile_num2=322)\n",
      "Pandas(ID=7, x=5708.735, y=99.6722, ra=230.2555992, dec=70.7470998, mag_r=15.712096, bands=22222, _7=nan, zspec=nan, lens=nan, lsb=nan, tile_num1=150, tile_num2=322)\n",
      "Pandas(ID=8, x=6033.1694, y=79.4746, ra=230.204836, dec=70.74602, mag_r=16.130112, bands=22222, _7=nan, zspec=nan, lens=nan, lsb=nan, tile_num1=150, tile_num2=322)\n",
      "Pandas(ID=9, x=6007.2246, y=72.6927, ra=230.2088988, dec=70.7456736, mag_r=17.306929, bands=22222, _7=nan, zspec=nan, lens=nan, lsb=nan, tile_num1=150, tile_num2=322)\n",
      "Pandas(ID=10, x=9329.25, y=61.6149, ra=229.6891101, dec=70.7439227, mag_r=16.817242, bands=22222, _7=nan, zspec=nan, lens=nan, lsb=nan, tile_num1=150, tile_num2=322)\n"
     ]
    }
   ],
   "source": [
    "tile_cat_test = tile_cat[:10].reset_index(drop=True)\n",
    "tile_cat_test = tensor_compatible(tile_cat_test)\n",
    "for row in tile_cat_test.itertuples(index=False):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "784f2676-deb8-4371-892b-59d17556c6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_row = torch.tensor(tile_cat_test.values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "43db1f2a-942d-4034-9b9f-a25b1bf51490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0000e+00,  7.2161e+03,  2.0280e+02,  2.3002e+02,  7.0752e+01,\n",
       "         1.4493e+01,  2.2222e+04,  1.0000e+00, -9.3598e-05,         nan,\n",
       "                nan,  1.5000e+02,  3.2200e+02])"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_row[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16933ffc-6b7f-4052-8f31-657e6667a901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "2f4a3386-36b7-4fb9-a55d-008a0abffbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_binary(input_string):\n",
    "    # Define the standard order of letters\n",
    "    standard_letters = 'ugriz'\n",
    "    # Initialize the result as an empty string\n",
    "    result = ''\n",
    "    # Iterate over each letter in the standard order\n",
    "    for letter in standard_letters:\n",
    "        # Append '2' if the letter is in the input string, '1' otherwise\n",
    "        if letter in input_string:\n",
    "            result += '2'\n",
    "        else:\n",
    "            result += '1'\n",
    "    # Convert the binary string to a decimal integer\n",
    "    return np.int32(result)\n",
    "\n",
    "def split_tile_nums(df):\n",
    "    # Split the tuple into two separate columns\n",
    "    if type(df['tile'][0]) != tuple:\n",
    "        df['tile'] = df['tile'].apply(ast.literal_eval)\n",
    "    df['tile_num1'], df['tile_num2'] = zip(*df['tile'])\n",
    "    # Drop tile column\n",
    "    df.drop('tile', axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "def tensor_compatible(df):\n",
    "    # Convert band info to integer number, 2 -> present, 1 -> absent\n",
    "    if type(df['bands'][0]) == str:\n",
    "        df['bands'] = df['bands'].apply(convert_to_binary)\n",
    "    # Split tile numbers up to two different columns and delete the tile column\n",
    "    df = split_tile_nums(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "ce4bbac6-43d7-4aac-8430-25212e9ea36e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>mag_r</th>\n",
       "      <th>bands</th>\n",
       "      <th>class</th>\n",
       "      <th>zspec</th>\n",
       "      <th>lens</th>\n",
       "      <th>lsb</th>\n",
       "      <th>tile_num1</th>\n",
       "      <th>tile_num2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7216.1090</td>\n",
       "      <td>202.7967</td>\n",
       "      <td>230.019617</td>\n",
       "      <td>70.752128</td>\n",
       "      <td>14.492716</td>\n",
       "      <td>22222</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.000094</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150</td>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>7859.3310</td>\n",
       "      <td>145.4179</td>\n",
       "      <td>229.919001</td>\n",
       "      <td>70.748950</td>\n",
       "      <td>14.938880</td>\n",
       "      <td>22222</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.000207</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150</td>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2550.8567</td>\n",
       "      <td>149.6538</td>\n",
       "      <td>230.749830</td>\n",
       "      <td>70.749313</td>\n",
       "      <td>18.307415</td>\n",
       "      <td>22222</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.225017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150</td>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5071.8354</td>\n",
       "      <td>138.8921</td>\n",
       "      <td>230.355269</td>\n",
       "      <td>70.749157</td>\n",
       "      <td>15.693336</td>\n",
       "      <td>22222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150</td>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>7765.2320</td>\n",
       "      <td>132.1593</td>\n",
       "      <td>229.933742</td>\n",
       "      <td>70.748301</td>\n",
       "      <td>18.250532</td>\n",
       "      <td>22222</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.076809</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150</td>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>3870.8833</td>\n",
       "      <td>101.8959</td>\n",
       "      <td>230.543211</td>\n",
       "      <td>70.747163</td>\n",
       "      <td>17.612999</td>\n",
       "      <td>22222</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.183967</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150</td>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>5708.7350</td>\n",
       "      <td>99.6722</td>\n",
       "      <td>230.255599</td>\n",
       "      <td>70.747100</td>\n",
       "      <td>15.712096</td>\n",
       "      <td>22222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150</td>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>6033.1694</td>\n",
       "      <td>79.4746</td>\n",
       "      <td>230.204836</td>\n",
       "      <td>70.746020</td>\n",
       "      <td>16.130112</td>\n",
       "      <td>22222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150</td>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>6007.2246</td>\n",
       "      <td>72.6927</td>\n",
       "      <td>230.208899</td>\n",
       "      <td>70.745674</td>\n",
       "      <td>17.306929</td>\n",
       "      <td>22222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150</td>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>9329.2500</td>\n",
       "      <td>61.6149</td>\n",
       "      <td>229.689110</td>\n",
       "      <td>70.743923</td>\n",
       "      <td>16.817242</td>\n",
       "      <td>22222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150</td>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID          x         y          ra        dec      mag_r  bands  class  \\\n",
       "0   1  7216.1090  202.7967  230.019617  70.752128  14.492716  22222    1.0   \n",
       "1   2  7859.3310  145.4179  229.919001  70.748950  14.938880  22222    1.0   \n",
       "2   3  2550.8567  149.6538  230.749830  70.749313  18.307415  22222    2.0   \n",
       "3   4  5071.8354  138.8921  230.355269  70.749157  15.693336  22222    NaN   \n",
       "4   5  7765.2320  132.1593  229.933742  70.748301  18.250532  22222    2.0   \n",
       "5   6  3870.8833  101.8959  230.543211  70.747163  17.612999  22222    2.0   \n",
       "6   7  5708.7350   99.6722  230.255599  70.747100  15.712096  22222    NaN   \n",
       "7   8  6033.1694   79.4746  230.204836  70.746020  16.130112  22222    NaN   \n",
       "8   9  6007.2246   72.6927  230.208899  70.745674  17.306929  22222    NaN   \n",
       "9  10  9329.2500   61.6149  229.689110  70.743923  16.817242  22222    NaN   \n",
       "\n",
       "      zspec  lens  lsb  tile_num1  tile_num2  \n",
       "0 -0.000094   NaN  NaN        150        322  \n",
       "1 -0.000207   NaN  NaN        150        322  \n",
       "2  0.225017   NaN  NaN        150        322  \n",
       "3       NaN   NaN  NaN        150        322  \n",
       "4  0.076809   NaN  NaN        150        322  \n",
       "5  0.183967   NaN  NaN        150        322  \n",
       "6       NaN   NaN  NaN        150        322  \n",
       "7       NaN   NaN  NaN        150        322  \n",
       "8       NaN   NaN  NaN        150        322  \n",
       "9       NaN   NaN  NaN        150        322  "
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_compatible(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "431de2de-d411-414a-beac-e783a98d9e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = '[(123,456),(111,222)]'\n",
    "test_eval = ast.literal_eval(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2462771d-d917-4171-b40d-76f5f5e8dc3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(123, 456), (111, 222)]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47bf915-a258-4d65-a4a9-5194e1490855",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
