{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdb62f0f-b4c2-4c74-9ab5-eafd5c315399",
   "metadata": {},
   "source": [
    "# FITS Dataloader\n",
    "\n",
    "A dataloader that iterates through a directory of fits files that contain images large patches of the sky using different colour bands.\n",
    "\n",
    "Each sample that the dataloader returns will be an array of cutouts from a given patch with all requested bands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4724246d-69ab-4314-8fdc-8bcee86f6605",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-04T21:00:47.963342Z",
     "iopub.status.busy": "2024-02-04T21:00:47.963029Z",
     "iopub.status.idle": "2024-02-04T21:00:50.608363Z",
     "shell.execute_reply": "2024-02-04T21:00:50.607520Z",
     "shell.execute_reply.started": "2024-02-04T21:00:47.963286Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/arc/home/obriaint/.local/lib/python3.10/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/arc/home/obriaint/.local/lib/python3.10/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import h5py\n",
    "from torchvision.transforms import v2\n",
    "import glob\n",
    "from astropy.io import fits\n",
    "\n",
    "def build_fits_dataloader(fits_path, bands, norm_type, batch_size, num_workers,\n",
    "                     img_size=64, pix_mean=None, pix_std=None, \n",
    "                     augment=False, shuffle=True):\n",
    "\n",
    "    if augment:\n",
    "        transforms = v2.Compose([v2.GaussianBlur(kernel_size=5, sigma=(0.1,1.5)),\n",
    "                                 v2.RandomResizedCrop(size=(img_size, img_size), scale=(0.8,1), antialias=True),\n",
    "                                 v2.RandomHorizontalFlip(p=0.5),\n",
    "                                 v2.RandomVerticalFlip(p=0.5)])\n",
    "    else:\n",
    "        transforms = None\n",
    "    \n",
    "    # Data loaders\n",
    "    dataset = FitsDataset(fits_path, bands=bands, img_size=img_size,\n",
    "                          batch_size=batch_size, shuffle=shuffle,\n",
    "                          norm=norm_type, transform=transforms,\n",
    "                          global_mean=pix_mean, global_std=pix_std)\n",
    "\n",
    "    return torch.utils.data.DataLoader(dataset, batch_size=1, \n",
    "                                       shuffle=shuffle, num_workers=num_workers,\n",
    "                                       pin_memory=True)\n",
    "\n",
    "def find_HSC_bands(fits_path, bands):\n",
    "    '''An HSC specific function that returns a list of file paths with all of the requested bands.'''\n",
    "\n",
    "    # Look for fits files\n",
    "    fits_files = sorted(glob.glob(f\"{fits_path}/calexp-HSC-*.fits\"))\n",
    "    \n",
    "    # Convert '/arc/projects/ots/pdr3_dud/calexp-HSC-I-9707-4%2C0.fits' to 9707-4%2C0.fits\n",
    "    unique_patches = list(set(['-'.join(x.split('-')[-2:]) for x in fits_files]))\n",
    "    unique_patches = sorted(unique_patches)\n",
    "    \n",
    "    # Make it hashable\n",
    "    set_fits_files = set(fits_files)\n",
    "\n",
    "    # Sort file names\n",
    "    filenames = []\n",
    "    for t in unique_patches:\n",
    "        potential_files = [f'{fits_path}/calexp-HSC-{b}-{t}' for b in bands]\n",
    "\n",
    "        # `f in set_fits_files` is O(n) if fits_files is a list,\n",
    "        # ~O(1) if fits_files is a hash table\n",
    "        if (all([f in set_fits_files for f in potential_files])):\n",
    "            filenames.append(potential_files)\n",
    "    print(f\"Found {len(filenames)} patches with the {bands} bands.\")\n",
    "\n",
    "    return filenames\n",
    "\n",
    "def split_3d_array(input_array, img_size, overlap):\n",
    "    \"\"\"\n",
    "    Split a larger 3D numpy array into a batch of smaller cutouts.\n",
    "\n",
    "    Args:\n",
    "    - input_array: The larger 3D numpy array of shape (C, H, W).\n",
    "    - img_size: The desired size of each cutout in both height and width.\n",
    "    - overlap: The overlap between adjacent cutouts as a fraction (0 to 1).\n",
    "\n",
    "    Returns:\n",
    "    - A numpy array of shape (N, C, img_size, img_size), where N is the number of cutouts.\n",
    "    \"\"\"\n",
    "    C, H, W = input_array.shape\n",
    "    batch_size = int((H / (img_size - img_size * overlap)) * (W / (img_size - img_size * overlap)))\n",
    "    \n",
    "    cutout_list = []\n",
    "    \n",
    "    for _ in range(batch_size):\n",
    "        h_start = np.random.randint(0, H - img_size + 1)\n",
    "        w_start = np.random.randint(0, W - img_size + 1)\n",
    "        \n",
    "        cutout = input_array[:, h_start:h_start+img_size, w_start:w_start+img_size]\n",
    "        cutout_list.append(cutout)\n",
    "    \n",
    "    return np.array(cutout_list)\n",
    "\n",
    "class FitsDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    \"\"\"\n",
    "    Dataset loader for the cutout datasets.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, fits_path, bands=['G','R','I','Z','Y'], img_size=64, overlap=0.,\n",
    "                 batch_size=64, shuffle=True, norm=None, transform=None, \n",
    "                 global_mean=0.1, global_std=2., pixel_min=None, pixel_max=None):\n",
    "        \n",
    "        self.fits_path = fits_path\n",
    "        self.img_size = img_size\n",
    "        self.overlap = overlap\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.norm = norm\n",
    "        self.transform = transform\n",
    "        self.global_mean = global_mean\n",
    "        self.global_std = global_std \n",
    "        self.pixel_min = pixel_min\n",
    "        self.pixel_max = pixel_max\n",
    "\n",
    "        # Find names of patch fits files\n",
    "        self.band_filenames = find_HSC_bands(fits_path, bands)\n",
    "                        \n",
    "    def __len__(self):\n",
    "        # The number of fits patches with all of the requested bands\n",
    "        return len(self.band_filenames)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        # Grab fits filenames\n",
    "        patch_filenames = self.band_filenames[idx]\n",
    "        \n",
    "        # Load all channels of the patch of sky\n",
    "        cutouts = []\n",
    "        for fn in patch_filenames:\n",
    "            cutouts.append(fits.open(fn, mode='readonly')[1].data)\n",
    "        # Organize into (C, H, W)\n",
    "        cutouts = np.array(cutouts)\n",
    "\n",
    "        # Split into a grid of cutouts based on img_size and overlap\n",
    "        cutouts = split_3d_array(cutouts, self.img_size, self.overlap)\n",
    "\n",
    "        # Shuffle images\n",
    "        if self.shuffle:\n",
    "            permutation = np.random.permutation(cutouts.shape[0])\n",
    "            cutouts = cutouts[permutation]\n",
    "\n",
    "        # Remove any NaN pixel values\n",
    "        cutouts[np.isnan(cutouts)] = 0.\n",
    "\n",
    "        # Clip pixel values\n",
    "        if self.pixel_min is not None:\n",
    "            cutouts[cutouts<self.pixel_min] = self.pixel_min\n",
    "        if self.pixel_max is not None:\n",
    "            cutouts[cutouts>self.pixel_max] = self.pixel_max\n",
    "\n",
    "        # Apply any augmentations\n",
    "        cutouts = torch.from_numpy(cutouts)\n",
    "        if self.transform is not None:\n",
    "            cutouts = self.transform(cutouts)\n",
    "            \n",
    "        if self.norm=='minmax':\n",
    "            # Normalize each sample between 0 and 1\n",
    "            sample_min = torch.amin(cutouts, dim=(1,2,3), keepdim=True)\n",
    "            sample_max = torch.amax(cutouts, dim=(1,2,3), keepdim=True)\n",
    "            cutouts = (cutouts - sample_min) / (sample_max - sample_min + 1e-6)\n",
    "        elif self.norm=='zscore':\n",
    "            # Normalize each sample to have zero mean and unit variance\n",
    "            sample_mean = torch.mean(cutouts, dim=(1,2,3), keepdim=True)\n",
    "            sample_std = torch.std(cutouts, dim=(1,2,3), keepdim=True)\n",
    "            cutouts = (cutouts - sample_mean) / (sample_std + 1e-6)\n",
    "        elif self.norm=='global':\n",
    "            # Normalize dataset to have zero mean and unit variance\n",
    "            cutouts = (cutouts - self.global_mean) / self.global_std\n",
    "\n",
    "        # Sort into M batches of batch_size\n",
    "        M = cutouts.shape[0] // self.batch_size\n",
    "        C = cutouts.shape[1]\n",
    "        cutouts = cutouts[:M * self.batch_size].reshape((M, self.batch_size, C, self.img_size, self.img_size))\n",
    "\n",
    "        return cutouts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d386d3d2-79ee-47b2-b7d7-7a77a52fcf14",
   "metadata": {},
   "source": [
    "## Construct the dataloader\n",
    "\n",
    "Increasing `num_workers` will allow you to load the next patch while training on the current one. However, it probably shouldn't be increased too high or else you will quickly run out of RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f70c38d5-f39e-4857-9813-dbb58a9deeb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-04T21:00:50.609958Z",
     "iopub.status.busy": "2024-02-04T21:00:50.609559Z",
     "iopub.status.idle": "2024-02-04T21:00:50.658608Z",
     "shell.execute_reply": "2024-02-04T21:00:50.657811Z",
     "shell.execute_reply.started": "2024-02-04T21:00:50.609928Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1477 patches with the ['G', 'R', 'I', 'Z', 'Y'] bands.\n"
     ]
    }
   ],
   "source": [
    "fits_path = '/arc/projects/ots/pdr3_dud'\n",
    "bands = ['G','R','I','Z','Y']\n",
    "norm_type = 'minmax'\n",
    "batch_size = 8\n",
    "num_workers = 0\n",
    "img_size = 64\n",
    "\n",
    "dataloader = build_fits_dataloader(fits_path, bands, norm_type, batch_size, num_workers,\n",
    "                                   img_size=img_size, pix_mean=None, pix_std=None, augment=True, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0293ef1e-cef5-4ee7-b404-ba9259e7730c",
   "metadata": {},
   "source": [
    "## Example usage\n",
    "\n",
    "The outer loop loads a bunch of batches - all from the same patch in the sky - and the inner loop iterates through each batch, which allows you to do your training on one batch at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7dfffc6-a1c3-4545-8554-5779b706896b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-04T21:00:50.659935Z",
     "iopub.status.busy": "2024-02-04T21:00:50.659645Z",
     "iopub.status.idle": "2024-02-04T21:01:00.531042Z",
     "shell.execute_reply": "2024-02-04T21:01:00.530057Z",
     "shell.execute_reply.started": "2024-02-04T21:00:50.659894Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This patch of sky created cutouts with the shape: torch.Size([538, 8, 5, 64, 64])\n",
      "Each batch has the shape: torch.Size([8, 5, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "# Iterate through dataloader\n",
    "for sample_batches in dataloader:    \n",
    "    # Iterate through each batch of images in this patch of the sky\n",
    "    print('This patch of sky created cutouts with the shape:', sample_batches[0].shape)\n",
    "    for batch in sample_batches[0]:\n",
    "        # Move batch to GPU and do your training stuff here\n",
    "        pass\n",
    "    print('Each batch has the shape:', batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ac4003-d78c-48f7-adcc-7a5c51283dbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
