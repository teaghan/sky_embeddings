2024-07-27 04:47:40,586 - INFO - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2024-07-27 04:47:40,586 - INFO - NumExpr defaulting to 8 threads.
2024-07-27 04:48:31,877 - INFO - From rank 0/1: initializing process group..
2024-07-27 04:48:32,450 - INFO - From rank 1/1: distributed training available: True and initialized: True
2024-07-27 04:48:32,450 - INFO - From rank 1/1: world size: 2; rank: 1; local rank: 1
2024-07-27 04:48:32,450 - INFO - Rank 1: CUDA_VISIBLE_DEVICES: 1
2024-07-27 04:48:32,450 - INFO - Rank 1: number of GPUs visible: 1
2024-07-27 04:48:32,450 - INFO - Rank 1: local rank: 1: world size: 2
2024-07-27 04:48:34,441 - INFO - Using AdamW
2024-07-27 04:48:34,443 - INFO - Starting fresh model to train...
2024-07-27 04:48:34,468 - INFO - From rank 1/1: initializing models..
2024-07-27 04:48:35,067 - INFO - From rank 1/1: models initialized.
2024-07-27 04:48:35,070 - INFO - Rank 1/1 passed the synchronization barrier.
2024-07-27 04:48:36,426 - INFO - Rank 1 handles indices from 9 to 17
2024-07-27 04:48:36,427 - INFO - Rank 1: worker 2855575 loading tile 6 for cutout 0.
2024-07-27 04:48:45,546 - INFO - Rank 1: worker 2855575 prepared tile 6 in 9.12 seconds.
2024-07-27 04:48:49,330 - INFO - Rank 1: worker 2855575 loading tile 10 for cutout 0.
2024-07-27 04:48:58,071 - INFO - Rank 1: worker 2855575 prepared tile 10 in 8.74 seconds.
2024-07-27 04:49:00,120 - INFO - Rank 1: worker 2855575 loading tile 3 for cutout 0.
2024-07-27 04:49:08,338 - INFO - Rank 1: worker 2855575 prepared tile 3 in 8.22 seconds.
2024-07-27 04:49:10,814 - INFO - Rank 1: worker 2855575 loading tile 9 for cutout 0.
2024-07-27 04:49:19,421 - INFO - Rank 1: worker 2855575 prepared tile 9 in 8.61 seconds.
2024-07-27 04:49:19,861 - INFO - Rank 1: About to enter barrier before validation.
2024-07-27 04:49:19,861 - INFO - Rank 1: Passed barrier before validation.
2024-07-27 04:49:19,861 - INFO - Rank 1: About to enter second barrier
2024-07-27 04:49:20,063 - INFO - Rank 1/1 passed the synchronization barrier after validation.
8:32,239 - INFO -   weight_decay: 0.04
2024-07-27 04:48:32,239 - INFO -   final_weight_decay: 0.4
2024-07-27 04:48:32,239 - INFO -   loss_fn: smooth_l1_loss
2024-07-27 04:48:32,239 - INFO -   start_lr: 0.0002
2024-07-27 04:48:32,239 - INFO -   ref_lr: 0.001
2024-07-27 04:48:32,239 - INFO -   final_lr: 1.0e-06
2024-07-27 04:48:32,239 - INFO -   final_lr_factor: 10000000.0
2024-07-27 04:48:32,239 - INFO -   norm_pix_loss: False
2024-07-27 04:48:32,239 - INFO -   use_bfloat16: True
2024-07-27 04:48:32,239 - INFO - MASK
2024-07-27 04:48:32,239 - INFO -   allow_overlap: False
2024-07-27 04:48:32,239 - INFO -   aspect_ratio_targets: [0.75, 1.5]
2024-07-27 04:48:32,239 - INFO -   min_keep: 5
2024-07-27 04:48:32,239 - INFO -   num_enc_masks: 1
2024-07-27 04:48:32,239 - INFO -   num_pred_masks: 4
2024-07-27 04:48:32,239 - INFO -   enc_mask_scale: [0.85, 1.0]
2024-07-27 04:48:32,239 - INFO -   pred_mask_scale: [0.15, 0.2]
2024-07-27 04:48:32,239 - INFO -   max_mask_ratio: 0.9
2024-07-27 04:48:32,239 - INFO -   mask_ratio: 0.75
2024-07-27 04:48:32,239 - INFO - ARCHITECTURE
2024-07-27 04:48:32,239 - INFO -   num_channels: 9
2024-07-27 04:48:32,239 - INFO -   patch_size: 8
2024-07-27 04:48:32,239 - INFO -   model_type: jepa_vit_small
2024-07-27 04:48:32,239 - INFO -   pred_depth: 4
2024-07-27 04:48:32,240 - INFO -   pred_emb_dim: 192
2024-07-27 04:48:32,240 - INFO -   attn_pool: False
2024-07-27 04:48:32,240 - INFO -   ra_dec: True
2024-07-27 04:48:32,240 - INFO -   embed_dim: 1024
2024-07-27 04:48:32,240 - INFO - LOGGING
2024-07-27 04:48:32,240 - INFO -   level: DEBUG
2024-07-27 04:48:32,240 - INFO - Notes
2024-07-27 04:48:32,240 - INFO -   comment: Initial I-JEPA training.
2024-07-27 04:48:33,931 - INFO - Using AdamW
2024-07-27 04:48:33,934 - INFO - Starting fresh model to train...
2024-07-27 04:48:33,953 - INFO - From rank 0/1: initializing models..
2024-07-27 04:48:35,067 - INFO - From rank 0/1: models initialized.
2024-07-27 04:48:35,070 - INFO - Rank 0/1 passed the synchronization barrier.
2024-07-27 04:48:35,151 - INFO - Found 18 patches with at least 9 of the ['G', 'I', 'R', 'Y', 'Z', 'NB0387', 'NB0816', 'NB0921', 'NB1010'] bands.
2024-07-27 04:48:35,178 - INFO - Training the network with a batch size of 64 per GPU ...
2024-07-27 04:48:35,179 - INFO - Progress will be displayed every 100 batch iterations and the model will be saved every 10.0 minutes.
2024-07-27 04:48:35,179 - INFO - Starting training loop...
2024-07-27 04:48:36,426 - INFO - Rank 0 handles indices from 0 to 8
2024-07-27 04:48:36,428 - INFO - Rank 0: worker 2855576 loading tile 15 for cutout 0.
2024-07-27 04:48:45,489 - INFO - Rank 0: worker 2855576 prepared tile 15 in 9.06 seconds.
2024-07-27 04:48:47,593 - INFO - Iter: 2: avg. loss 0.442425
2024-07-27 04:48:47,675 - INFO - Iter: 3: avg. loss 0.406954
2024-07-27 04:48:47,749 - INFO - Iter: 4: avg. loss 0.380635
2024-07-27 04:48:47,809 - INFO - Iter: 5: avg. loss 0.359068
2024-07-27 04:48:47,870 - INFO - Iter: 6: avg. loss 0.340671
2024-07-27 04:48:47,937 - INFO - Iter: 7: avg. loss 0.323031
2024-07-27 04:48:48,005 - INFO - Iter: 8: avg. loss 0.306057
2024-07-27 04:48:48,063 - INFO - Iter: 9: avg. loss 0.289978
2024-07-27 04:48:48,135 - INFO - Iter: 10: avg. loss 0.274660
2024-07-27 04:48:48,208 - INFO - Iter: 11: avg. loss 0.261196
2024-07-27 04:48:48,269 - INFO - Iter: 12: avg. loss 0.248532
2024-07-27 04:48:48,331 - INFO - Iter: 13: avg. loss 0.236803
2024-07-27 04:48:48,392 - INFO - Iter: 14: avg. loss 0.226303
2024-07-27 04:48:48,465 - INFO - Iter: 15: avg. loss 0.216583
2024-07-27 04:48:48,529 - INFO - Iter: 16: avg. loss 0.207648
2024-07-27 04:48:48,582 - INFO - Iter: 17: avg. loss 0.199561
2024-07-27 04:48:48,641 - INFO - Iter: 18: avg. loss 0.192131
2024-07-27 04:48:48,701 - INFO - Iter: 19: avg. loss 0.185356
2024-07-27 04:48:48,767 - INFO - Iter: 20: avg. loss 0.178679
2024-07-27 04:48:48,825 - INFO - Iter: 21: avg. loss 0.172460
2024-07-27 04:48:48,891 - INFO - Iter: 22: avg. loss 0.166700
2024-07-27 04:48:48,952 - INFO - Iter: 23: avg. loss 0.162558
2024-07-27 04:48:49,013 - INFO - Iter: 24: avg. loss 0.158650
2024-07-27 04:48:49,084 - INFO - Iter: 25: avg. loss 0.156080
2024-07-27 04:48:49,144 - INFO - Iter: 26: avg. loss 0.152533
2024-07-27 04:48:49,203 - INFO - Iter: 27: avg. loss 0.148240
2024-07-27 04:48:49,272 - INFO - Iter: 28: avg. loss 0.144292
2024-07-27 04:48:49,327 - INFO - Iter: 29: avg. loss 0.140932
2024-07-27 04:48:49,342 - INFO - Rank 0: worker 2855576 loading tile 1 for cutout 0.
2024-07-27 04:48:49,387 - INFO - Iter: 30: avg. loss 0.137279
2024-07-27 04:48:49,444 - INFO - Iter: 31: avg. loss 0.133473
2024-07-27 04:48:49,506 - INFO - Iter: 32: avg. loss 0.130016
2024-07-27 04:48:49,578 - INFO - Iter: 33: avg. loss 0.126925
2024-07-27 04:48:58,243 - INFO - Rank 0: worker 2855576 prepared tile 1 in 8.90 seconds.
2024-07-27 04:48:58,391 - INFO - Iter: 34: avg. loss 0.123878
2024-07-27 04:48:58,462 - INFO - Iter: 35: avg. loss 0.120956
2024-07-27 04:48:58,521 - INFO - Iter: 36: avg. loss 0.117989
2024-07-27 04:48:58,581 - INFO - Iter: 37: avg. loss 0.115133
2024-07-27 04:48:58,644 - INFO - Iter: 38: avg. loss 0.112450
2024-07-27 04:48:58,712 - INFO - Iter: 39: avg. loss 0.109900
2024-07-27 04:48:58,771 - INFO - Iter: 40: avg. loss 0.107493
2024-07-27 04:48:58,850 - INFO - Iter: 41: avg. loss 0.105130
2024-07-27 04:48:58,917 - INFO - Iter: 42: avg. loss 0.102797
2024-07-27 04:48:58,986 - INFO - Iter: 43: avg. loss 0.100559
2024-07-27 04:48:59,035 - INFO - Iter: 44: avg. loss 0.098439
2024-07-27 04:48:59,095 - INFO - Iter: 45: avg. loss 0.096421
2024-07-27 04:48:59,157 - INFO - Iter: 46: avg. loss 0.094524
2024-07-27 04:48:59,220 - INFO - Iter: 47: avg. loss 0.092622
2024-07-27 04:48:59,281 - INFO - Iter: 48: avg. loss 0.090823
2024-07-27 04:48:59,349 - INFO - Iter: 49: avg. loss 0.089046
2024-07-27 04:48:59,409 - INFO - Iter: 50: avg. loss 0.087363
2024-07-27 04:48:59,487 - INFO - Iter: 51: avg. loss 0.085759
2024-07-27 04:48:59,550 - INFO - Iter: 52: avg. loss 0.084194
2024-07-27 04:48:59,607 - INFO - Iter: 53: avg. loss 0.082647
2024-07-27 04:48:59,668 - INFO - Iter: 54: avg. loss 0.081175
2024-07-27 04:48:59,730 - INFO - Iter: 55: avg. loss 0.079752
2024-07-27 04:48:59,797 - INFO - Iter: 56: avg. loss 0.078370
2024-07-27 04:48:59,857 - INFO - Iter: 57: avg. loss 0.077033
2024-07-27 04:48:59,927 - INFO - Iter: 58: avg. loss 0.075764
2024-07-27 04:48:59,991 - INFO - Iter: 59: avg. loss 0.074497
2024-07-27 04:49:00,052 - INFO - Iter: 60: avg. loss 0.073285
2024-07-27 04:49:00,112 - INFO - Iter: 61: avg. loss 0.072097
2024-07-27 04:49:00,113 - INFO - Rank 0: worker 2855576 loading tile 16 for cutout 0.
2024-07-27 04:49:00,169 - INFO - Iter: 62: avg. loss 0.070958
2024-07-27 04:49:00,239 - INFO - Iter: 63: avg. loss 0.069840
2024-07-27 04:49:00,303 - INFO - Iter: 64: avg. loss 0.068780
2024-07-27 04:49:08,434 - INFO - Iter: 65: avg. loss 0.067766
2024-07-27 04:49:08,966 - INFO - Rank 0: worker 2855576 prepared tile 16 in 8.85 seconds.
2024-07-27 04:49:09,091 - INFO - Iter: 66: avg. loss 0.066749
2024-07-27 04:49:09,164 - INFO - Iter: 67: avg. loss 0.065788
2024-07-27 04:49:09,229 - INFO - Iter: 68: avg. loss 0.064845
2024-07-27 04:49:09,284 - INFO - Iter: 69: avg. loss 0.063923
2024-07-27 04:49:09,354 - INFO - Iter: 70: avg. loss 0.063024
2024-07-27 04:49:09,417 - INFO - Iter: 71: avg. loss 0.062146
2024-07-27 04:49:09,468 - INFO - Iter: 72: avg. loss 0.061305
2024-07-27 04:49:09,528 - INFO - Iter: 73: avg. loss 0.060473
2024-07-27 04:49:09,587 - INFO - Iter: 74: avg. loss 0.059670
2024-07-27 04:49:09,656 - INFO - Iter: 75: avg. loss 0.058879
2024-07-27 04:49:09,715 - INFO - Iter: 76: avg. loss 0.058112
2024-07-27 04:49:09,773 - INFO - Iter: 77: avg. loss 0.057386
2024-07-27 04:49:09,831 - INFO - Iter: 78: avg. loss 0.056659
2024-07-27 04:49:09,891 - INFO - Iter: 79: avg. loss 0.055958
2024-07-27 04:49:09,953 - INFO - Iter: 80: avg. loss 0.055318
2024-07-27 04:49:10,019 - INFO - Iter: 81: avg. loss 0.054669
2024-07-27 04:49:10,093 - INFO - Iter: 82: avg. loss 0.054027
2024-07-27 04:49:10,161 - INFO - Iter: 83: avg. loss 0.053387
2024-07-27 04:49:10,220 - INFO - Iter: 84: avg. loss 0.052780
2024-07-27 04:49:10,279 - INFO - Iter: 85: avg. loss 0.052165
2024-07-27 04:49:10,342 - INFO - Iter: 86: avg. loss 0.051566
2024-07-27 04:49:10,404 - INFO - Iter: 87: avg. loss 0.050975
2024-07-27 04:49:10,484 - INFO - Iter: 88: avg. loss 0.050405
2024-07-27 04:49:10,558 - INFO - Iter: 89: avg. loss 0.049858
2024-07-27 04:49:10,615 - INFO - Iter: 90: avg. loss 0.049314
2024-07-27 04:49:10,674 - INFO - Iter: 91: avg. loss 0.048782
2024-07-27 04:49:10,733 - INFO - Iter: 92: avg. loss 0.048265
2024-07-27 04:49:10,798 - INFO - Iter: 93: avg. loss 0.047785
2024-07-27 04:49:10,809 - INFO - Rank 0: worker 2855576 loading tile 2 for cutout 0.
2024-07-27 04:49:10,857 - INFO - Iter: 94: avg. loss 0.047280
2024-07-27 04:49:10,928 - INFO - Iter: 95: avg. loss 0.046811
2024-07-27 04:49:10,986 - INFO - Iter: 96: avg. loss 0.046328
2024-07-27 04:49:11,058 - INFO - Iter: 97: avg. loss 0.045866
2024-07-27 04:49:19,486 - INFO - Rank 0: worker 2855576 prepared tile 2 in 8.68 seconds.
2024-07-27 04:49:19,634 - INFO - Iter: 98: avg. loss 0.045411
2024-07-27 04:49:19,709 - INFO - Iter: 99: avg. loss 0.045003
2024-07-27 04:49:19,790 - INFO - Iter: 100: avg. loss 0.044555
2024-07-27 04:49:19,859 - INFO - Rank 0: About to enter barrier before validation.
2024-07-27 04:49:19,869 - INFO - Rank 0: Passed barrier before validation.
2024-07-27 04:49:19,869 - INFO - Rank 0: performing validation at iteration 100
2024-07-27 04:49:20,033 - INFO - Rank 0: validating at iteration 100 on batch 0
2024-07-27 04:59:22,170 - ERROR - Rank 0: Validation failed at iteration 100: [Rank 0] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=814, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600009 milliseconds before timing out.
2024-07-27 04:59:22,171 - INFO - Rank 0: About to enter second barrier
